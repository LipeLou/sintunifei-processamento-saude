{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ecf6d53",
      "metadata": {},
      "source": [
        "# 3. Preencher Dados de CPF e Dependencia\n",
        "\n",
        "Este notebook identifica beneficiarios com CPF ou DEPENDENCIA vazios, busca os dados na base da Unimed e gera arquivos de apoio para preenchimento e validacao.\n",
        "\n",
        "**Entradas necessarias:**\n",
        "- Planilha de dados (`dados.xlsx`) na aba do mes de referencia\n",
        "- Planilha de beneficiarios ativos da Unimed (`beneficiarios_ativos.xls`)\n",
        "\n",
        "**Saidas:**\n",
        "- Arquivo `beneficiarios_preenchimento.xlsx` (base para preenchimento)\n",
        "- Arquivo `dados_preenchidos.xlsx` (dados com CPF/DEPENDENCIA preenchidos)\n",
        "- Arquivo `nomes_nao_encontrados.xlsx` (familias nao encontradas na base da Unimed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69a535d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "caminho_dados = '../Data/'                  # Caminho para a planilha de dados           \n",
        "caminho_beneficiarios_ativos = '../Data/'   # Caminho para a planilha de beneficiarios ativos  \n",
        "mes = ''                                    # Mês Atual                                         \n",
        "\n",
        "\n",
        "dados = pd.read_excel(caminho_dados, skiprows=1, sheet_name=mes)\n",
        "ativos = pd.read_excel(caminho_beneficiarios_ativos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59edf38",
      "metadata": {},
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "\n",
        "caminho_preenchimento = '../Data/beneficiarios_preenchimento.xlsx'\n",
        "\n",
        "colunas_esperadas = {'NOME', 'CPF', 'DEPENDENCIA'}\n",
        "if not colunas_esperadas.issubset(dados.columns):\n",
        "    raise ValueError(f\"Planilha de dados sem as colunas esperadas: {colunas_esperadas}\")\n",
        "if not colunas_esperadas.issubset(ativos.columns):\n",
        "    raise ValueError(f\"Planilha da Unimed sem as colunas esperadas: {colunas_esperadas}\")\n",
        "\n",
        "filtro_pendentes = (\n",
        "    dados['NOME'].notna()\n",
        "    & (dados['NOME'].astype(str).str.strip() != '')\n",
        "    & (dados['CPF'].isna() | dados['DEPENDENCIA'].isna())\n",
        ")\n",
        "\n",
        "pendentes = dados.loc[filtro_pendentes, ['NOME', 'CPF', 'DEPENDENCIA']].copy()\n",
        "nomes_pendentes = pendentes['NOME'].astype(str).str.strip().drop_duplicates().tolist()\n",
        "\n",
        "pendentes['NOME_CHAVE'] = pendentes['NOME'].astype(str).str.strip().str.upper()\n",
        "ativos_aux = ativos.copy()\n",
        "ativos_aux['NOME_CHAVE'] = ativos_aux['NOME'].astype(str).str.strip().str.upper()\n",
        "\n",
        "resultado = (\n",
        "    ativos_aux[ativos_aux['NOME_CHAVE'].isin(pendentes['NOME_CHAVE'])]\n",
        "    [['NOME', 'DEPENDENCIA', 'CPF']]\n",
        "    .drop_duplicates()\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "resultado.to_excel(caminho_preenchimento, index=False)\n",
        "\n",
        "print(f'Total de nomes pendentes encontrados nos dados: {len(nomes_pendentes)}')\n",
        "print(f'Total de registros encontrados na Unimed: {len(resultado)}')\n",
        "print(f'Arquivo gerado: {caminho_preenchimento}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9834cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "caminho_saida_preenchido = '../Data/dados_preenchidos.xlsx'\n",
        "caminho_saida_nao_encontrados = '../Data/nomes_nao_encontrados.xlsx'\n",
        "\n",
        "dados_original = pd.read_excel(caminho_dados, skiprows=1, sheet_name=mes)\n",
        "preenchimento = pd.read_excel(caminho_preenchimento)\n",
        "\n",
        "\n",
        "def normalizar_nome_coluna(nome):\n",
        "    nome = str(nome).strip().upper()\n",
        "    nome = ''.join(\n",
        "        c for c in unicodedata.normalize('NFKD', nome)\n",
        "        if not unicodedata.combining(c)\n",
        "    )\n",
        "    return ' '.join(nome.split())\n",
        "\n",
        "\n",
        "def mapear_colunas(df, colunas_requeridas):\n",
        "    mapa_normalizado = {normalizar_nome_coluna(c): c for c in df.columns}\n",
        "    mapeamento = {}\n",
        "    faltando = []\n",
        "\n",
        "    for col in colunas_requeridas:\n",
        "        chave = normalizar_nome_coluna(col)\n",
        "        if chave in mapa_normalizado:\n",
        "            mapeamento[col] = mapa_normalizado[chave]\n",
        "        else:\n",
        "            faltando.append(col)\n",
        "\n",
        "    if faltando:\n",
        "        raise ValueError(f'Colunas ausentes na planilha: {faltando}')\n",
        "\n",
        "    return mapeamento\n",
        "\n",
        "\n",
        "colunas_dados_desejadas = ['CÓD DA FAMILIA', 'CARTEIRA', 'DEPENDENCIA', 'NOME', 'CPF']\n",
        "mapa_dados = mapear_colunas(dados_original, colunas_dados_desejadas)\n",
        "mapa_preenchimento = mapear_colunas(preenchimento, ['NOME', 'CPF', 'DEPENDENCIA'])\n",
        "\n",
        "col_cod_familia = mapa_dados['CÓD DA FAMILIA']\n",
        "col_carteira = mapa_dados['CARTEIRA']\n",
        "col_dependencia = mapa_dados['DEPENDENCIA']\n",
        "col_nome = mapa_dados['NOME']\n",
        "col_cpf = mapa_dados['CPF']\n",
        "\n",
        "col_nome_p = mapa_preenchimento['NOME']\n",
        "col_cpf_p = mapa_preenchimento['CPF']\n",
        "col_dependencia_p = mapa_preenchimento['DEPENDENCIA']\n",
        "\n",
        "dados_preenchidos = dados_original.copy()\n",
        "dados_preenchidos['NOME_CHAVE'] = dados_preenchidos[col_nome].astype(str).str.strip().str.upper()\n",
        "preenchimento_aux = preenchimento.copy()\n",
        "preenchimento_aux['NOME_CHAVE'] = preenchimento_aux[col_nome_p].astype(str).str.strip().str.upper()\n",
        "\n",
        "preenchimento_por_nome = (\n",
        "    preenchimento_aux.groupby('NOME_CHAVE', as_index=False)\n",
        "    .agg({\n",
        "        col_cpf_p: lambda s: s.dropna().iloc[0] if not s.dropna().empty else pd.NA,\n",
        "        col_dependencia_p: lambda s: s.dropna().iloc[0] if not s.dropna().empty else pd.NA,\n",
        "    })\n",
        "    .rename(columns={\n",
        "        col_cpf_p: 'CPF_NOVO',\n",
        "        col_dependencia_p: 'DEPENDENCIA_NOVO'\n",
        "    })\n",
        ")\n",
        "\n",
        "merge = dados_preenchidos.merge(\n",
        "    preenchimento_por_nome,\n",
        "    on='NOME_CHAVE',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "cpf_vazio = merge[col_cpf].isna()\n",
        "dependencia_vazia = merge[col_dependencia].isna()\n",
        "\n",
        "merge.loc[cpf_vazio, col_cpf] = merge.loc[cpf_vazio, 'CPF_NOVO']\n",
        "merge.loc[dependencia_vazia, col_dependencia] = merge.loc[dependencia_vazia, 'DEPENDENCIA_NOVO']\n",
        "\n",
        "mask_com_pendencia = (\n",
        "    merge[col_nome].notna()\n",
        "    & (merge[col_nome].astype(str).str.strip() != '')\n",
        "    & (dados_original[col_cpf].isna() | dados_original[col_dependencia].isna())\n",
        ")\n",
        "\n",
        "mask_nao_encontrado = (\n",
        "    mask_com_pendencia\n",
        "    & merge['CPF_NOVO'].isna()\n",
        "    & merge['DEPENDENCIA_NOVO'].isna()\n",
        ")\n",
        "\n",
        "familias_nao_encontradas = merge.loc[mask_nao_encontrado, col_cod_familia].dropna().unique()\n",
        "\n",
        "familia_completa = merge[merge[col_cod_familia].isin(familias_nao_encontradas)]\n",
        "sem_familia = merge[mask_nao_encontrado & merge[col_cod_familia].isna()]\n",
        "\n",
        "nao_encontrados_final = (\n",
        "    pd.concat([familia_completa, sem_familia], ignore_index=True)\n",
        "    [[col_cod_familia, col_carteira, col_dependencia, col_nome, col_cpf]]\n",
        "    .drop_duplicates()\n",
        "    .rename(columns={\n",
        "        col_cod_familia: 'CÓD DA FAMILIA',\n",
        "        col_carteira: 'CARTEIRA',\n",
        "        col_dependencia: 'DEPENDENCIA',\n",
        "        col_nome: 'NOME',\n",
        "        col_cpf: 'CPF'\n",
        "    })\n",
        "    .sort_values(['CÓD DA FAMILIA', 'NOME'], na_position='last')\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "colunas_saida = ['CÓD DA FAMILIA', 'CARTEIRA', 'DEPENDENCIA', 'NOME', 'CPF']\n",
        "blocos_familia = []\n",
        "\n",
        "for _, grupo in nao_encontrados_final.groupby('CÓD DA FAMILIA', dropna=False, sort=False):\n",
        "    blocos_familia.append(grupo)\n",
        "    blocos_familia.append(pd.DataFrame([{col: pd.NA for col in colunas_saida}]))\n",
        "\n",
        "if blocos_familia:\n",
        "    nao_encontrados_formatado = pd.concat(blocos_familia, ignore_index=True).iloc[:-1].reset_index(drop=True)\n",
        "else:\n",
        "    nao_encontrados_formatado = nao_encontrados_final.copy()\n",
        "\n",
        "saida_final = merge.drop(columns=['NOME_CHAVE', 'CPF_NOVO', 'DEPENDENCIA_NOVO'])\n",
        "saida_final.to_excel(caminho_saida_preenchido, index=False)\n",
        "nao_encontrados_formatado.to_excel(caminho_saida_nao_encontrados, index=False)\n",
        "\n",
        "print(f'Arquivo preenchido gerado: {caminho_saida_preenchido}')\n",
        "print(f'Nomes nao encontrados gerado: {caminho_saida_nao_encontrados}')\n",
        "print(f'Total de registros nao encontrados (familia completa): {len(nao_encontrados_final)}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
